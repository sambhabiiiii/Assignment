{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Data Import & Overview\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Limit to top 8000 most common words\n",
        "NUM_WORDS = 8000\n",
        "(raw_train_X, raw_train_y), (raw_test_X, raw_test_y) = imdb.load_data(num_words=NUM_WORDS)\n",
        "\n",
        "# Merge train/test so we can shuffle/split ourselves\n",
        "X_all = np.concatenate((raw_train_X, raw_test_X), axis=0)\n",
        "y_all = np.concatenate((raw_train_y, raw_test_y), axis=0)\n",
        "\n",
        "print(\"Total reviews:\", len(X_all))\n",
        "print(\"Label distribution:\", pd.Series(y_all).value_counts())\n",
        "\n",
        "# Create reverse word mapping\n",
        "word_map = imdb.get_word_index()\n",
        "idx_to_word = {idx + 3: word for word, idx in word_map.items()}\n",
        "idx_to_word[0] = \"<PAD>\"\n",
        "idx_to_word[1] = \"<START>\"\n",
        "idx_to_word[2] = \"<UNK>\"\n",
        "\n",
        "def decode_review(encoded_review):\n",
        "    return \" \".join([idx_to_word.get(i, \"?\") for i in encoded_review])\n",
        "\n",
        "# Example decoded review\n",
        "print(\"\\nSample Review:\\n\", decode_review(X_all[0]))\n",
        "print(\"Label:\", y_all[0])\n",
        "\n",
        "\n",
        "# Preprocessing Function\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(review_text):\n",
        "    text = review_text.lower()\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(w) for w in words if w not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# Decode & preprocess\n",
        "decoded_reviews = [decode_review(r) for r in X_all]\n",
        "processed_reviews = [preprocess(r) for r in decoded_reviews]\n",
        "\n",
        "# Split into train/test sets\n",
        "train_X, test_X, train_y, test_y = train_test_split(\n",
        "    processed_reviews, y_all, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "#  Feature Extraction\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=6000, ngram_range=(1, 2))\n",
        "train_vectors = vectorizer.fit_transform(train_X)\n",
        "test_vectors = vectorizer.transform(test_X)\n",
        "\n",
        "print(\"Feature matrix shape:\", train_vectors.shape)\n",
        "\n",
        "#  Train & Evaluate Models\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
        "    \"Bernoulli NB\": BernoulliNB(),\n",
        "    \"SVM\": LinearSVC()\n",
        "}\n",
        "\n",
        "metrics_data = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(train_vectors, train_y)\n",
        "    preds = model.predict(test_vectors)\n",
        "    acc = accuracy_score(test_y, preds)\n",
        "    prec = precision_score(test_y, preds)\n",
        "    rec = recall_score(test_y, preds)\n",
        "    f1 = f1_score(test_y, preds)\n",
        "    metrics_data.append([name, acc, prec, rec, f1])\n",
        "    print(f\"\\n{name} Confusion Matrix:\\n\", confusion_matrix(test_y, preds))\n",
        "\n",
        "# Metrics table\n",
        "metrics_df = pd.DataFrame(metrics_data, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "print(\"\\nModel Comparison:\\n\", metrics_df)\n",
        "\n",
        "\n",
        "#  Pipeline Approach\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer(stop_words=\"english\", max_features=5000)),\n",
        "    (\"clf\", LogisticRegression(max_iter=300))\n",
        "])\n",
        "\n",
        "pipeline.fit(train_X, train_y)\n",
        "print(\"\\nPipeline Accuracy:\", accuracy_score(test_y, pipeline.predict(test_X)))\n",
        "\n",
        "\n",
        "#  Manual Inference\n",
        "\n",
        "\n",
        "custom_reviews = [\n",
        "    \"I absolutely loved this movie! The performances were breathtaking.\",\n",
        "    \"The movie was too long and extremely boring.\",\n",
        "    \"A masterpiece! Definitely one of the best films I've ever seen.\",\n",
        "    \"Terrible plot and bad acting, I do not recommend.\",\n",
        "    \"An okay film, some parts were great but others were dull.\"\n",
        "]\n",
        "\n",
        "custom_reviews_processed = [preprocess(r) for r in custom_reviews]\n",
        "predictions = pipeline.predict(custom_reviews_processed)\n",
        "\n",
        "for review, label in zip(custom_reviews, predictions):\n",
        "    print(f\"\\nReview: {review}\")\n",
        "    print(\"Predicted Sentiment:\", \"Positive\" if label == 1 else \"Negative\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I9RXVikSjwc",
        "outputId": "5bdccaef-f55d-4f0e-800b-170ca0f392b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reviews: 50000\n",
            "Label distribution: 1    25000\n",
            "0    25000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample Review:\n",
            " <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Label: 1\n",
            "Feature matrix shape: (25000, 6000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 200 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=200).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[10750  1685]\n",
            " [ 1807 10758]]\n",
            "\n",
            "Bernoulli NB Confusion Matrix:\n",
            " [[10525  1910]\n",
            " [ 1792 10773]]\n",
            "\n",
            "SVM Confusion Matrix:\n",
            " [[10433  2002]\n",
            " [ 2271 10294]]\n",
            "\n",
            "Model Comparison:\n",
            "                  Model  Accuracy  Precision    Recall        F1\n",
            "0  Logistic Regression   0.86032   0.864582  0.856188  0.860365\n",
            "1         Bernoulli NB   0.85192   0.849405  0.857382  0.853375\n",
            "2                  SVM   0.82908   0.837183  0.819260  0.828124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 300 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=300).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pipeline Accuracy: 0.86012\n",
            "\n",
            "Review: I absolutely loved this movie! The performances were breathtaking.\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Review: The movie was too long and extremely boring.\n",
            "Predicted Sentiment: Negative\n",
            "\n",
            "Review: A masterpiece! Definitely one of the best films I've ever seen.\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Review: Terrible plot and bad acting, I do not recommend.\n",
            "Predicted Sentiment: Negative\n",
            "\n",
            "Review: An okay film, some parts were great but others were dull.\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    }
  ]
}